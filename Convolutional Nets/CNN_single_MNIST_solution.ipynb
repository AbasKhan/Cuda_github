{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataType float32 for attr 'T' not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-839db05415a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mbc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_conv1_filter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mwf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input_height\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_conv1_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mbf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/abbas/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_normal\u001b[1;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[0;32m     76\u001b[0m     rnd = gen_random_ops._random_standard_normal(shape_tensor, dtype,\n\u001b[0;32m     77\u001b[0m                                                  \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                                                  seed2=seed2)\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0mmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/abbas/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36m_random_standard_normal\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    107\u001b[0m   result = _op_def_lib.apply_op(\"RandomStandardNormal\", shape=shape,\n\u001b[0;32m    108\u001b[0m                                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                                 name=name)\n\u001b[0m\u001b[0;32m    110\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/abbas/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbase_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m--> 530\u001b[1;33m                                        _Attr(op_def, input_arg.type_attr))\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/abbas/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def)\u001b[0m\n\u001b[0;32m     59\u001b[0m           \u001b[1;34m\"DataType %s for attr '%s' not in list of allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m           (dtypes.as_dtype(dtype).name, attr_def.name,\n\u001b[1;32m---> 61\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: DataType float32 for attr 'T' not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "n_input_width = 28\n",
    "n_input_height = 28\n",
    "n_input_channel = 1\n",
    "training_epochs = 100\n",
    "batch_size = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_conv1_patch_size = 3 \n",
    "n_conv1_filter = 84\n",
    "\n",
    "n_output  = 10 # e.g. MNIST total classes (0-9 digits)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input_width * n_input_height])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "wc1 = tf.Variable(tf.random_normal([n_conv1_patch_size, n_conv1_patch_size, n_input_channel, n_conv1_filter], stddev=0.1))\n",
    "bc1 = tf.Variable(tf.random_normal([n_conv1_filter], stddev=0.1))\n",
    "\n",
    "wf1 = tf.Variable(tf.random_normal([(n_input_width/2)*(n_input_height/2)*n_conv1_filter, n_output], stddev=0.1))\n",
    "bf1 = tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "\n",
    "# Reshape input\n",
    "input_r = tf.reshape(x, shape=[-1, n_input_width, n_input_width, 1])\n",
    "# Convolution\n",
    "conv = tf.nn.conv2d(input_r, wc1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# Add-bias\n",
    "bias = tf.nn.bias_add(conv, bc1)\n",
    "# Pass ReLu\n",
    "relu = tf.nn.relu(bias)\n",
    "# Max-pooling\n",
    "pool  = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Vectorize\n",
    "dense = tf.reshape(pool, [-1, wf1.get_shape().as_list()[0]])\n",
    "# Fully-connected layer\n",
    "out = tf.add(tf.matmul(dense, wf1), bf1)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(out, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 , batch Loss= 9.698008, Training Accuracy= 0.21400\n",
      "Epoch   1 , batch Loss= 13.315502, Training Accuracy= 0.10800\n",
      "Epoch   2 , batch Loss= 6.820310, Training Accuracy= 0.18200\n",
      "Epoch   3 , batch Loss= 6.497667, Training Accuracy= 0.22800\n",
      "Epoch   4 , batch Loss= 6.326646, Training Accuracy= 0.36400\n",
      "Epoch   5 , batch Loss= 6.054041, Training Accuracy= 0.32400\n",
      "Epoch   6 , batch Loss= 4.208635, Training Accuracy= 0.37600\n",
      "Epoch   7 , batch Loss= 2.933131, Training Accuracy= 0.52800\n",
      "Epoch   8 , batch Loss= 2.522697, Training Accuracy= 0.39200\n",
      "Epoch   9 , batch Loss= 1.602883, Training Accuracy= 0.52600\n",
      "Epoch   10 , batch Loss= 1.322742, Training Accuracy= 0.58200\n",
      "Epoch   11 , batch Loss= 1.133940, Training Accuracy= 0.60200\n",
      "Epoch   12 , batch Loss= 1.157976, Training Accuracy= 0.60400\n",
      "Epoch   13 , batch Loss= 1.147177, Training Accuracy= 0.61400\n",
      "Epoch   14 , batch Loss= 1.041107, Training Accuracy= 0.67000\n",
      "Epoch   15 , batch Loss= 0.880427, Training Accuracy= 0.73000\n",
      "Epoch   16 , batch Loss= 0.727180, Training Accuracy= 0.77800\n",
      "Epoch   17 , batch Loss= 0.586651, Training Accuracy= 0.81400\n",
      "Epoch   18 , batch Loss= 0.621644, Training Accuracy= 0.80600\n",
      "Epoch   19 , batch Loss= 0.649994, Training Accuracy= 0.79000\n",
      "Epoch   20 , batch Loss= 0.530925, Training Accuracy= 0.79800\n",
      "Epoch   21 , batch Loss= 0.634857, Training Accuracy= 0.78000\n",
      "Epoch   22 , batch Loss= 0.494220, Training Accuracy= 0.83000\n",
      "Epoch   23 , batch Loss= 0.412952, Training Accuracy= 0.86600\n",
      "Epoch   24 , batch Loss= 0.387836, Training Accuracy= 0.85400\n",
      "Epoch   25 , batch Loss= 0.470188, Training Accuracy= 0.85000\n",
      "Epoch   26 , batch Loss= 0.341088, Training Accuracy= 0.88600\n",
      "Epoch   27 , batch Loss= 0.278117, Training Accuracy= 0.93000\n",
      "Epoch   28 , batch Loss= 0.328409, Training Accuracy= 0.90800\n",
      "Epoch   29 , batch Loss= 0.291398, Training Accuracy= 0.91400\n",
      "Epoch   30 , batch Loss= 0.369559, Training Accuracy= 0.89000\n",
      "Epoch   31 , batch Loss= 0.404229, Training Accuracy= 0.88400\n",
      "Epoch   32 , batch Loss= 0.256603, Training Accuracy= 0.92400\n",
      "Epoch   33 , batch Loss= 0.195759, Training Accuracy= 0.94400\n",
      "Epoch   34 , batch Loss= 0.257331, Training Accuracy= 0.92200\n",
      "Epoch   35 , batch Loss= 0.343872, Training Accuracy= 0.89000\n",
      "Epoch   36 , batch Loss= 0.229345, Training Accuracy= 0.93400\n",
      "Epoch   37 , batch Loss= 0.256835, Training Accuracy= 0.91800\n",
      "Epoch   38 , batch Loss= 0.260628, Training Accuracy= 0.92600\n",
      "Epoch   39 , batch Loss= 0.280729, Training Accuracy= 0.92200\n",
      "Epoch   40 , batch Loss= 0.209217, Training Accuracy= 0.93200\n",
      "Epoch   41 , batch Loss= 0.219680, Training Accuracy= 0.93800\n",
      "Epoch   42 , batch Loss= 0.232981, Training Accuracy= 0.93400\n",
      "Epoch   43 , batch Loss= 0.289932, Training Accuracy= 0.93600\n",
      "Epoch   44 , batch Loss= 0.205512, Training Accuracy= 0.93200\n",
      "Epoch   45 , batch Loss= 0.243695, Training Accuracy= 0.93800\n",
      "Epoch   46 , batch Loss= 0.216716, Training Accuracy= 0.94400\n",
      "Epoch   47 , batch Loss= 0.215997, Training Accuracy= 0.94000\n",
      "Epoch   48 , batch Loss= 0.223372, Training Accuracy= 0.94600\n",
      "Epoch   49 , batch Loss= 0.251316, Training Accuracy= 0.92200\n",
      "Epoch   50 , batch Loss= 0.182107, Training Accuracy= 0.93800\n",
      "Epoch   51 , batch Loss= 0.229468, Training Accuracy= 0.92800\n",
      "Epoch   52 , batch Loss= 0.250945, Training Accuracy= 0.93000\n",
      "Epoch   53 , batch Loss= 0.236762, Training Accuracy= 0.94600\n",
      "Epoch   54 , batch Loss= 0.257318, Training Accuracy= 0.91400\n",
      "Epoch   55 , batch Loss= 0.160791, Training Accuracy= 0.95800\n",
      "Epoch   56 , batch Loss= 0.179038, Training Accuracy= 0.95000\n",
      "Epoch   57 , batch Loss= 0.117824, Training Accuracy= 0.97200\n",
      "Epoch   58 , batch Loss= 0.124134, Training Accuracy= 0.96400\n",
      "Epoch   59 , batch Loss= 0.193575, Training Accuracy= 0.94200\n",
      "Epoch   60 , batch Loss= 0.146478, Training Accuracy= 0.96200\n",
      "Epoch   61 , batch Loss= 0.139071, Training Accuracy= 0.94600\n",
      "Epoch   62 , batch Loss= 0.173732, Training Accuracy= 0.95400\n",
      "Epoch   63 , batch Loss= 0.141940, Training Accuracy= 0.95200\n",
      "Epoch   64 , batch Loss= 0.322429, Training Accuracy= 0.92000\n",
      "Epoch   65 , batch Loss= 0.184123, Training Accuracy= 0.95400\n",
      "Epoch   66 , batch Loss= 0.124469, Training Accuracy= 0.96000\n",
      "Epoch   67 , batch Loss= 0.153880, Training Accuracy= 0.95200\n",
      "Epoch   68 , batch Loss= 0.178244, Training Accuracy= 0.94600\n",
      "Epoch   69 , batch Loss= 0.139726, Training Accuracy= 0.95200\n",
      "Epoch   70 , batch Loss= 0.126303, Training Accuracy= 0.96800\n",
      "Epoch   71 , batch Loss= 0.123882, Training Accuracy= 0.96400\n",
      "Epoch   72 , batch Loss= 0.186553, Training Accuracy= 0.94600\n",
      "Epoch   73 , batch Loss= 0.129437, Training Accuracy= 0.95800\n",
      "Epoch   74 , batch Loss= 0.166613, Training Accuracy= 0.94600\n",
      "Epoch   75 , batch Loss= 0.169805, Training Accuracy= 0.95600\n",
      "Epoch   76 , batch Loss= 0.126167, Training Accuracy= 0.94800\n",
      "Epoch   77 , batch Loss= 0.153130, Training Accuracy= 0.95800\n",
      "Epoch   78 , batch Loss= 0.156355, Training Accuracy= 0.94600\n",
      "Epoch   79 , batch Loss= 0.129903, Training Accuracy= 0.97000\n",
      "Epoch   80 , batch Loss= 0.137360, Training Accuracy= 0.95200\n",
      "Epoch   81 , batch Loss= 0.177389, Training Accuracy= 0.94800\n",
      "Epoch   82 , batch Loss= 0.207589, Training Accuracy= 0.94400\n",
      "Epoch   83 , batch Loss= 0.092347, Training Accuracy= 0.97000\n",
      "Epoch   84 , batch Loss= 0.161707, Training Accuracy= 0.94200\n",
      "Epoch   85 , batch Loss= 0.126843, Training Accuracy= 0.96000\n",
      "Epoch   86 , batch Loss= 0.106542, Training Accuracy= 0.96200\n",
      "Epoch   87 , batch Loss= 0.099119, Training Accuracy= 0.97400\n",
      "Epoch   88 , batch Loss= 0.147413, Training Accuracy= 0.95800\n",
      "Epoch   89 , batch Loss= 0.183568, Training Accuracy= 0.94400\n",
      "Epoch   90 , batch Loss= 0.180632, Training Accuracy= 0.94800\n",
      "Epoch   91 , batch Loss= 0.135231, Training Accuracy= 0.97600\n",
      "Epoch   92 , batch Loss= 0.095140, Training Accuracy= 0.97000\n",
      "Epoch   93 , batch Loss= 0.135315, Training Accuracy= 0.96800\n",
      "Epoch   94 , batch Loss= 0.148824, Training Accuracy= 0.96600\n",
      "Epoch   95 , batch Loss= 0.158154, Training Accuracy= 0.95600\n",
      "Epoch   96 , batch Loss= 0.092840, Training Accuracy= 0.97400\n",
      "Epoch   97 , batch Loss= 0.140681, Training Accuracy= 0.95800\n",
      "Epoch   98 , batch Loss= 0.080091, Training Accuracy= 0.97600\n",
      "Epoch   99 , batch Loss= 0.119037, Training Accuracy= 0.97000\n",
      "Optimization Finished!\n",
      "Testing Accuracy:"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,28,28,84]\n\t [[Node: BiasAdd_2 = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Conv2D_2, Variable_9/read)]]\nCaused by op u'BiasAdd_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-839db05415a2>\", line 30, in <module>\n    bias = tf.nn.bias_add(conv, bc1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 131, in bias_add\n    return gen_nn_ops._bias_add(value, bias, data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 193, in _bias_add\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7da6002a85f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Calculate accuracy mnist test images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     print \"Testing Accuracy:\",         sess.run(accuracy, feed_dict={x: mnist.test.images,\n\u001b[1;32m---> 19\u001b[1;33m                                       \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                                       })\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 659\u001b[1;33m                                             e.code)\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,28,28,84]\n\t [[Node: BiasAdd_2 = BiasAdd[T=DT_FLOAT, data_format=\"NHWC\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Conv2D_2, Variable_9/read)]]\nCaused by op u'BiasAdd_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-839db05415a2>\", line 30, in <module>\n    bias = tf.nn.bias_add(conv, bc1)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py\", line 131, in bias_add\n    return gen_nn_ops._bias_add(value, bias, data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 193, in _bias_add\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 655, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2154, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1154, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    for epoch in range(training_epochs):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y\n",
    "                                                          })\n",
    "        print \"Epoch  \" ,epoch  ,\", batch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Calculate accuracy mnist test images\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                      y: mnist.test.labels\n",
    "                                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
