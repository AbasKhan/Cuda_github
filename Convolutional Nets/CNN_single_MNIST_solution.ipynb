{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_input_width = 28\n",
    "n_input_height = 28\n",
    "n_input_channel = 1\n",
    "training_epochs = 100\n",
    "batch_size = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "n_conv1_patch_size = 3 \n",
    "n_conv1_filter = 84\n",
    "\n",
    "n_output  = 10 # e.g. MNIST total classes (0-9 digits)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input_width * n_input_height])\n",
    "y = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "wc1 = tf.Variable(tf.random_normal([n_conv1_patch_size, n_conv1_patch_size, n_input_channel, n_conv1_filter], stddev=0.1))\n",
    "bc1 = tf.Variable(tf.random_normal([n_conv1_filter], stddev=0.1))\n",
    "\n",
    "wf1 = tf.Variable(tf.random_normal([(n_input_width/2)*(n_input_height/2)*n_conv1_filter, n_output], stddev=0.1))\n",
    "bf1 = tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "\n",
    "# Reshape input\n",
    "input_r = tf.reshape(x, shape=[-1, n_input_width, n_input_width, 1])\n",
    "# Convolution\n",
    "conv = tf.nn.conv2d(input_r, wc1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# Add-bias\n",
    "bias = tf.nn.bias_add(conv, bc1)\n",
    "# Pass ReLu\n",
    "relu = tf.nn.relu(bias)\n",
    "# Max-pooling\n",
    "pool  = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Vectorize\n",
    "dense = tf.reshape(pool, [-1, wf1.get_shape().as_list()[0]])\n",
    "# Fully-connected layer\n",
    "out = tf.add(tf.matmul(dense, wf1), bf1)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(out, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 , Minibatch Loss= 6.036530, Training Accuracy= 0.15600\n",
      "Epoch   1 , Minibatch Loss= 11.040858, Training Accuracy= 0.19200\n",
      "Epoch   2 , Minibatch Loss= 11.840248, Training Accuracy= 0.09400\n",
      "Epoch   3 , Minibatch Loss= 6.688283, Training Accuracy= 0.28200\n",
      "Epoch   4 , Minibatch Loss= 5.790600, Training Accuracy= 0.11800\n",
      "Epoch   5 , Minibatch Loss= 4.669760, Training Accuracy= 0.13200\n",
      "Epoch   6 , Minibatch Loss= 3.899807, Training Accuracy= 0.20400\n",
      "Epoch   7 , Minibatch Loss= 3.039432, Training Accuracy= 0.24800\n",
      "Epoch   8 , Minibatch Loss= 2.742738, Training Accuracy= 0.27200\n",
      "Epoch   9 , Minibatch Loss= 2.412395, Training Accuracy= 0.24800\n",
      "Epoch   10 , Minibatch Loss= 2.118133, Training Accuracy= 0.34800\n",
      "Epoch   11 , Minibatch Loss= 1.741504, Training Accuracy= 0.35400\n",
      "Epoch   12 , Minibatch Loss= 1.324258, Training Accuracy= 0.49400\n",
      "Epoch   13 , Minibatch Loss= 1.231168, Training Accuracy= 0.56800\n",
      "Epoch   14 , Minibatch Loss= 0.898669, Training Accuracy= 0.71800\n",
      "Epoch   15 , Minibatch Loss= 0.974576, Training Accuracy= 0.66800\n",
      "Epoch   16 , Minibatch Loss= 0.980072, Training Accuracy= 0.64000\n",
      "Epoch   17 , Minibatch Loss= 0.898903, Training Accuracy= 0.70400\n",
      "Epoch   18 , Minibatch Loss= 0.797229, Training Accuracy= 0.74000\n",
      "Epoch   19 , Minibatch Loss= 0.715803, Training Accuracy= 0.75600\n",
      "Epoch   20 , Minibatch Loss= 0.487254, Training Accuracy= 0.84000\n",
      "Epoch   21 , Minibatch Loss= 0.525796, Training Accuracy= 0.84400\n",
      "Epoch   22 , Minibatch Loss= 0.434602, Training Accuracy= 0.86200\n",
      "Epoch   23 , Minibatch Loss= 0.443855, Training Accuracy= 0.86600\n",
      "Epoch   24 , Minibatch Loss= 0.447058, Training Accuracy= 0.86400\n",
      "Epoch   25 , Minibatch Loss= 0.501360, Training Accuracy= 0.84600\n",
      "Epoch   26 , Minibatch Loss= 0.294605, Training Accuracy= 0.92200\n",
      "Epoch   27 , Minibatch Loss= 0.273481, Training Accuracy= 0.93000\n",
      "Epoch   28 , Minibatch Loss= 0.318192, Training Accuracy= 0.89400\n",
      "Epoch   29 , Minibatch Loss= 0.309834, Training Accuracy= 0.91000\n",
      "Epoch   30 , Minibatch Loss= 0.327791, Training Accuracy= 0.90800\n",
      "Epoch   31 , Minibatch Loss= 0.404905, Training Accuracy= 0.87400\n",
      "Epoch   32 , Minibatch Loss= 0.243510, Training Accuracy= 0.93400\n",
      "Epoch   33 , Minibatch Loss= 0.230149, Training Accuracy= 0.92600\n",
      "Epoch   34 , Minibatch Loss= 0.292578, Training Accuracy= 0.90400\n",
      "Epoch   35 , Minibatch Loss= 0.359834, Training Accuracy= 0.90200\n",
      "Epoch   36 , Minibatch Loss= 0.233921, Training Accuracy= 0.92600\n",
      "Epoch   37 , Minibatch Loss= 0.276475, Training Accuracy= 0.92200\n",
      "Epoch   38 , Minibatch Loss= 0.247023, Training Accuracy= 0.91400\n",
      "Epoch   39 , Minibatch Loss= 0.282729, Training Accuracy= 0.90800\n",
      "Epoch   40 , Minibatch Loss= 0.216179, Training Accuracy= 0.93200\n",
      "Epoch   41 , Minibatch Loss= 0.248759, Training Accuracy= 0.92800\n",
      "Epoch   42 , Minibatch Loss= 0.242687, Training Accuracy= 0.93000\n",
      "Epoch   43 , Minibatch Loss= 0.314571, Training Accuracy= 0.91800\n",
      "Epoch   44 , Minibatch Loss= 0.210577, Training Accuracy= 0.93200\n",
      "Epoch   45 , Minibatch Loss= 0.248719, Training Accuracy= 0.93000\n",
      "Epoch   46 , Minibatch Loss= 0.213181, Training Accuracy= 0.94800\n",
      "Epoch   47 , Minibatch Loss= 0.196958, Training Accuracy= 0.94200\n",
      "Epoch   48 , Minibatch Loss= 0.233482, Training Accuracy= 0.93400\n",
      "Epoch   49 , Minibatch Loss= 0.270497, Training Accuracy= 0.91400\n",
      "Epoch   50 , Minibatch Loss= 0.180774, Training Accuracy= 0.94400\n",
      "Epoch   51 , Minibatch Loss= 0.241508, Training Accuracy= 0.92400\n",
      "Epoch   52 , Minibatch Loss= 0.263167, Training Accuracy= 0.92000\n",
      "Epoch   53 , Minibatch Loss= 0.217891, Training Accuracy= 0.94400\n",
      "Epoch   54 , Minibatch Loss= 0.257123, Training Accuracy= 0.91400\n",
      "Epoch   55 , Minibatch Loss= 0.152970, Training Accuracy= 0.96200\n",
      "Epoch   56 , Minibatch Loss= 0.176477, Training Accuracy= 0.95600\n",
      "Epoch   57 , Minibatch Loss= 0.114918, Training Accuracy= 0.96600\n",
      "Epoch   58 , Minibatch Loss= 0.130627, Training Accuracy= 0.95800\n",
      "Epoch   59 , Minibatch Loss= 0.193492, Training Accuracy= 0.94400\n",
      "Epoch   60 , Minibatch Loss= 0.142520, Training Accuracy= 0.96800\n",
      "Epoch   61 , Minibatch Loss= 0.120435, Training Accuracy= 0.95600\n",
      "Epoch   62 , Minibatch Loss= 0.160751, Training Accuracy= 0.95400\n",
      "Epoch   63 , Minibatch Loss= 0.143817, Training Accuracy= 0.95400\n",
      "Epoch   64 , Minibatch Loss= 0.317707, Training Accuracy= 0.91600\n",
      "Epoch   65 , Minibatch Loss= 0.178116, Training Accuracy= 0.95600\n",
      "Epoch   66 , Minibatch Loss= 0.103347, Training Accuracy= 0.96400\n",
      "Epoch   67 , Minibatch Loss= 0.157255, Training Accuracy= 0.94800\n",
      "Epoch   68 , Minibatch Loss= 0.163285, Training Accuracy= 0.95600\n",
      "Epoch   69 , Minibatch Loss= 0.133912, Training Accuracy= 0.95000\n",
      "Epoch   70 , Minibatch Loss= 0.117688, Training Accuracy= 0.96800\n",
      "Epoch   71 , Minibatch Loss= 0.113636, Training Accuracy= 0.96400\n",
      "Epoch   72 , Minibatch Loss= 0.179632, Training Accuracy= 0.95400\n",
      "Epoch   73 , Minibatch Loss= 0.125246, Training Accuracy= 0.96600\n",
      "Epoch   74 , Minibatch Loss= 0.180426, Training Accuracy= 0.94200\n",
      "Epoch   75 , Minibatch Loss= 0.176336, Training Accuracy= 0.94200\n",
      "Epoch   76 , Minibatch Loss= 0.128689, Training Accuracy= 0.95200\n",
      "Epoch   77 , Minibatch Loss= 0.156381, Training Accuracy= 0.95600\n",
      "Epoch   78 , Minibatch Loss= 0.148697, Training Accuracy= 0.95000\n",
      "Epoch   79 , Minibatch Loss= 0.123446, Training Accuracy= 0.96400\n",
      "Epoch   80 , Minibatch Loss= 0.135097, Training Accuracy= 0.96000\n",
      "Epoch   81 , Minibatch Loss= 0.176278, Training Accuracy= 0.95000\n",
      "Epoch   82 , Minibatch Loss= 0.184082, Training Accuracy= 0.95000\n",
      "Epoch   83 , Minibatch Loss= 0.087012, Training Accuracy= 0.96800\n",
      "Epoch   84 , Minibatch Loss= 0.155971, Training Accuracy= 0.95200\n",
      "Epoch   85 , Minibatch Loss= 0.107749, Training Accuracy= 0.96800\n",
      "Epoch   86 , Minibatch Loss= 0.099366, Training Accuracy= 0.97200\n",
      "Epoch   87 , Minibatch Loss= 0.100835, Training Accuracy= 0.97200\n",
      "Epoch   88 , Minibatch Loss= 0.144208, Training Accuracy= 0.95400\n",
      "Epoch   89 , Minibatch Loss= 0.187017, Training Accuracy= 0.94800\n",
      "Epoch   90 , Minibatch Loss= 0.188932, Training Accuracy= 0.94800\n",
      "Epoch   91 , Minibatch Loss= 0.118490, Training Accuracy= 0.97400\n",
      "Epoch   92 , Minibatch Loss= 0.097450, Training Accuracy= 0.96800\n",
      "Epoch   93 , Minibatch Loss= 0.132711, Training Accuracy= 0.96800\n",
      "Epoch   94 , Minibatch Loss= 0.136216, Training Accuracy= 0.96600\n",
      "Epoch   95 , Minibatch Loss= 0.160360, Training Accuracy= 0.95000\n",
      "Epoch   96 , Minibatch Loss= 0.077040, Training Accuracy= 0.98000\n",
      "Epoch   97 , Minibatch Loss= 0.131505, Training Accuracy= 0.96200\n",
      "Epoch   98 , Minibatch Loss= 0.066566, Training Accuracy= 0.98600\n",
      "Epoch   99 , Minibatch Loss= 0.122291, Training Accuracy= 0.96800\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
